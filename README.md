# An implementation of PLVM: Personalize Large Vision-Language Model

Paper: https://arxiv.org/pdf/2412.17610

- [ ] Training code
- [x] Inference code

Checkpoint path: [link](https://drive.google.com/file/d/1_zdWlCXPem_RidqRW1Wt6yNe758Vovdv/view?usp=sharing)

Steps to do:
- This code is directly built on top of LLaVA. Please install [LLaVA](https://github.com/haotian-liu/LLaVA?tab=readme-ov-file#install).
- Download [YoLLaVA dataset](https://github.com/WisconsinAIVision/YoLLaVA)

Single-turn conversation:
- The single turn conversation can be done by using ``run_script.sh``.

Multi-turn conversation: Still debugging